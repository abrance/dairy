> magit
	>> emacs git插件
	>> 基本操作
		>>> https://github.com/coldnew/pangu-spacing#:~:text=These%20spaces%20between%20English%20and%20Chinese%20characters%20are,English%20and%20Chinese%20characters%20also%20have%20relationship%20problem.
		>>> http://jixiuf.github.io/blog/000100-emacs-magit.html/#org0edb6b1
		>>> https://zhuanlan.zhihu.com/p/57535366#:~:text=Emacs%20%E7%9A%84%20Magit%20%E6%89%A9%E5%B1%95%E6%8F%92%E4%BB%B6%E4%BD%BF%E5%BE%97%E4%BD%BF%E7%94%A8%20Git,%E8%BF%9B%E8%A1%8C%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%8F%98%E5%BE%97%E7%AE%80%E5%8D%95%E8%B5%B7%E6%9D%A5%E3%80%82%20Git%20%E6%98%AF%E4%B8%80%E4%B8%AA%E5%BE%88%E6%A3%92%E7%9A%84%E7%94%A8%E4%BA%8E%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E7%9A%84%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%20%E5%B7%A5%E5%85%B7%EF%BC%8C%E5%B0%B1%E6%98%AF%E6%96%B0%E4%BA%BA%E5%AD%A6%E4%B9%A0%E8%B5%B7%E6%9D%A5%E5%A4%AA%E9%9A%BE%E3%80%82
		>>> https://devbins.github.io/post/magit/
		>>> 注意git push 为 大写P

TODO
> Python, shell
	>> 浅拷贝和深拷贝
		>>> 通过等号拷贝：可变/不可变数据类型内存地址相同
		>>> 通过工厂方法拷贝：不可变数据类型内存地址相同，可变数据类型内存地址不同
		>>> 通过值传递拷贝：不可变数据类型不涉及，可变数据类型内存地址不同
		>>> 通过浅拷贝方法拷贝：不可变数据类型内存地址相同，可变数据类型内存地址不同
		>>> 通过深拷贝方法拷贝：不可变数据类型内存地址相同，可变数据类型内存地址不同
		deepcopy()
			深拷贝
			拷贝到最后一层，不可变对象的引用
		copy()
			浅拷贝
			只拷贝第一层的引用
	>> 高阶函数map reduce
		>>> map
			实现列表求平方
			ls = map(lambda x:x**2, [1, 2, 3, 4])
		>>> reduce
			实现阶乘
			res = reduce((lambda x, y: x*y), [1, 3, 5])   # > 15
	>> 迭代器与生成器
		>>> 函数内部使用yield而不是return语句返回结果。yield语句一次返回一个结果，在每个结果中间，挂起函数的状态，以便下次从它离开的地方继续执行。目的：产生一个迭代器

************************************************************
一.迭代器
------------------------------------------------------------
# 通过iter()方法获得了list的迭代器对象，然后就可以通过next()方法来访问list中的元素了。当容器中没有可访问的元素后，next()方法将会抛出一个StopIteration异常终止迭代器。
#encoding=utf-9
li=[5,6,7]
it=iter(li)
print it
print it.next()
print it.next()
print it.next()
print it.next()  #此次调用会抛异常

# 举例说明：将列表[1,2,3,4,5,6],生成字典，奇数位为key,偶数位为value
#coding=utf-8
''' 将列表[1,2,3,4,5,6],生成字典，奇数位为key,偶数位为value  '''
a = [1,2,3,4,5,6]
b={}
"普通方法"
for i in range(0,len(a),2):
    b[a[i]] = a[i+1]
print b
c=iter(a)
d={}
"迭代器"
for i in range(len(a)/2):
    key = c.next()
    value = c.next()
    d[key]=value
print d
------------------------------------------------------------
二.生成器
------------------------------------------------------------
# 如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器（Generator）

# 代码示例：
L = [x * x for x in range(10)]
print L
g = (x * x for x in range(10))
print g
print g.next()
print g.next()
for n in g:
	print n
# 举例说明; ps:yield 通常和生成器一起使用
# 代码示例：
def odd():
    print 'step 1'
    yield 1
    print 'step 2'
    yield 3
    print 'step 3'
    yield 5
o = odd()
print o.next()
print o.next()
print o.next()
#for i in o:
# print i #可以遍历执行函数

<<<step 1
<<<1
<<<step 2
<<<3
<<<step 3
<<<5
------------------------------------------------------------
************************************************************
	>> 装饰器和闭包
		>>> 闭包
			>>>> 使用外部函数变量的内部函数称为闭包，构成函数嵌套和使用外部变量的构成闭包的必要条件
			>>>> 应用场景
				>>>>> 可以在其他的执行上下文中，访问到函数的内部变量
		>>> 装饰器
************************************************************
装饰器实现锁
------------------------------------------------------------
def synchronized(func):
    func.__lock__ = threading.Lock()
    def lock_func(*args, **kwargs):
        with func.__lock__:
            return func(*args, **kwargs)
    return lock_func
------------------------------------------------------------
************************************************************
		
	>>实现单例模式
************************************************************
项目中的单例模式
------------------------------------------------------------
class Config(object):
    """
    多处用到配置类，用单例模式
    """
    instance = None
    @synchronized
    def __new__(cls):
        if __name__ != '__main__':
            _, module_name = os.path.split(sys.argv[0])
            file_name = module_name.split('.')[0]  # 后缀是py或pyc，后缀为exe时，运行可能不带exe
            module = sys.modules.get(__name__[-len(file_name):])  # 一定是同一个文件，因为实例化时进到这里
            if module:
                cls = getattr(module, cls.__name__)
        if cls.instance is None:
            cls.instance = super(Config, cls).__new__(cls)
        return cls.instance
------------------------------------------------------------
************************************************************

> Mysql, PostgreSQL, Redis
	>> SQL语句
	>> SQL 嵌套规则
	https://blog.csdn.net/u012129558/article/details/52351563
		>>>

	>> redis
	https://cloud.tencent.com/developer/article/1814536
		>>> C语言写的kv数据库，nosql，Redis的操作是原子性的，单进程单线程， redis 利用队列技术将并发访问变为串行访问， 消除了传统数据库串行控制的开销。
		>>> 5种数据类型，包括String，List，Set，Zset，Hash
		>>> 优势
			 (1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都很低
			 (2)支持丰富数据类型，支持string，list，set，sorted set，hash
			 (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
			 (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除
		
高并发和超卖问题

峰值有5000每秒的人，后端服务器面对这么多请求可能顶不住压力而造成服务器出现各种问题。任何商品都有库存，当出现高并发时，可能导致超卖问题。为了解决这两个问题，我们提出了解决方案。
　　B：静态化
　　将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。
　　C：限流
　　一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。
那么后端的数据库在高并发和超卖下会遇到什么问题呢？主要会有如下3个问题：（主要讨论写的问题，读的问题通过增加cache可以很容易的解决）
　　I：　首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差。
　　II： 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的。
　　III：最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低MySQL的处理性能，最终导致前端页面出现超时异常。
解决方案1：
　　将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。
　　优点：解决性能问题
　　缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险。
解决方案2：
　　引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。
　　优点：解决超卖问题，略微提升性能。
　　缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列。

解决方案3：
　　将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作（相比较MySQL的自增来说没有空洞），同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。
　　优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。
　　缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。

1.把你要卖出的商品比如10个商品放到缓存中；然后在memcache里设置一个计数器来记录请求数，这个请求书你可以以你要秒杀卖出的商品数为基数，比如你想卖出10个商品，只允许100个请求进来。那当计数器达到100的时候，后面进来的就显示秒杀结束，这样可以减轻你的服务器的压力。然后根据这100个请求，先付款的先得后付款的提示商品以秒杀完。
2. 必须使用缓存，将需要秒杀的商品放入缓存中，并使用锁来处理其并发情况。当接到用户秒杀提交订单的情况下，先将商品数量递减（加锁/解锁）后再进行其他方面的处理，处理失败再将数据递增1（加锁/解锁），否则表示交易成功。
当商品数量递减到0时，表示商品秒杀完毕，拒绝其他用户的请求。
3.使用redis的zset字段来存储商品以及表示它的库存，设置score值为库存量，利用它的原子自增性，当库存降为0则停止后面的后面的请求，提示商品已经卖完。		
	
> 超融合架构, ceph, 虚拟化
> pandas, numpy
> nginx

> 算法
> 遇到的问题

> TCP/IP
  >> ARP 协议

  >> ICMP协议

  >> IP分片

	>> 单播广播与组播

	>> IGMP

	>> TCP半关闭

io多路复用
https://www.cnblogs.com/Anker/p/3265058.html
https://baike.baidu.com/item/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/1180849
> 解决什么问题
	>> 做到资源的最大利用： 加入了一个中间层来管理 连接，而不是每个socket马上起一个线程连接(python httpsever就是这么干的)
> 多路复用定义：数据通信系统或计算机网络系统中，传输媒体的带宽或容量往往会大于传输单一信号的需求，为了有效地利用通信线路,希望一个信道同时传输多路信号，这就是所谓的多路复用技术。所以，多路指多路的信号，复用指信道的复用。在 网络io 多路复用中，多路指 多个socket，复用指，一个程序（线程）的复用
> 网络io多路复用
	>> IO多路复用在Linux下包括了三种，select、poll、epoll，抽象来看，他们功能是类似的，但具体细节各有不同：首先都会对一组文件描述符进行相关事件的注册，然后阻塞等待某些事件的发生或等待超时。IO多路复用都可以关注多个文件描述符，但对于这三种机制而言，不同数量级文件描述符对性能的影响是不同的。
	>> I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

