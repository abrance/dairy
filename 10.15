TODO
> 档案云打包
> 复习
	>>

复习
> 超融合架构, ceph, 虚拟化
> pandas, numpy
> nginx

> 算法
> 遇到的问题

复习书籍
> 命令行与shell脚本
> TCP/IP编程
> Linux高性能服务器编程

> 进程线程协程
	>> 进程
		 >>> 操作系统分配资源的基本单位。
		 >>> 切换开销大
		 >>> 操作系统为每个进程分配独立的内存，而统一进程的线程共享内存资源
		 >>> 进程是线程的容器
	>> 线程
		 >>> CPU调度基本单位
	>> 协程
	https://blog.csdn.net/lambert310/article/details/51162634
		 >>> 协程是一种用户级的轻量级线程。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。协程是用户自己来编写调度逻辑的，对CPU来说，协程其实是单线程，所以CPU不用去考虑怎么调度、切换上下文，这就省去了CPU的切换开销，所以协程在一定程度上又好于多线程。
		 >>> 线程相关的概念是抢占式多任务，而与协程相关的是协作式多任务
		 >>> gevent使用协程
		 		 gevent.sleep交出控制权
				 gevent.spawn 创建
	
> GIL的理解
	>> https://www.v2ex.com/t/777560
	>> GIL是应用和操作系统逐步从多任务单核心演进到多任务多核心导致的 , 单核CPU上调度多个线程任务，共享一个全局锁，只有正在执行的线程拥有这把锁，直到IO操作或者Timer Tick到期让出CPU
	>> 由于物理上的限制，CPU频率上提升难度大，所以现在采用多核CPU。为了有效利用多核CPU，出现了多线程编程的方式，但是使不同核心之间的L1、L2数据同步是个问题。
		 >>> intel的架构里，多核中每个核 L1 L2 cache 是独立的，但L3是共享的。
	>> 单进程里的多线程一般是可以并行与多核的。
	>> 历史遗留问题，目的是保护python虚拟机内部状态，python解释器有C写成的，C代码可以直接访问python对象，比如pylist_append这种操作不是原子行的，如果去掉了GIL锁，那么在并行的时候会使python程序在C中就崩溃。所以，要么在C的扩展中处处加锁，要么直接GIL锁。python出现时，还是单核CPU，根本不用考虑这个问题。
	>> 但是现实是python在web中只被用于做io密集型应用，所以GIL不会影响python在这方面的表现，反而是python强大的扩展库让python的生态更活跃。
	
> gc 垃圾回收机制
	>> 引用计数rc
		 >>> 优点：“实时性”，任何内存，一旦没有指向它的引用，就会立即被回收。缺点：循环引用问题
		 
	>> 标记清除
	https://blog.csdn.net/master_ning/article/details/80784656
		>>>
************************************************************
标记清除示例
------------------------------------------------------------
a = [1,2]
b = [3,4]
a.append(b)
b.append(a)
del a 
#第二组循环引用#
c = [4,5]
d = [5,6]
c.append(d)
d.append(c)
del c
del d
# 首先，他先划分出两拨，一拨叫root object(存活组)，一拨叫unreachable(死亡组)。然后，他把各个对象的引用计数复制出来，对这个副本进行引用环的摘除。摘除完毕，此时a的引用计数的副本是0，b的引用计数的副本是1，c和d的引用计数的副本都是0。那么先把副本为非0的放到存活组，副本为0的打入死亡组。如果就这样结束的话，就错杀了a了，因为b还要用，我们把a所引用的对象在内存中清除了b还能用吗？显然还得在审一遍，别把无辜的人也给杀了，于是他就在存活组里，对每个对象都分析一遍，由于目前存活组只有b，那么他只对b分析，因为b要存活，所以b里的元素也要存活，于是在b中就发现了原a所指向的对象，于是就把他从死亡组中解救出来。至此，进过了一审和二审，最终把所有的任然在死亡组中的对象通通杀掉，而root object继续存活。b所指向的对象引用计数任然是2，原a所指向的对象的引用计数仍然是1
------------------------------------------------------------
************************************************************
	>> 分代回收
		 >>> 将系统中的全部内存块依据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。也就是说，活得越长的对象。就越不可能是垃圾，就应该降低对它的垃圾收集频率。那么怎样来衡量这个存活时间：一般是利用几次垃圾收集动作来衡量，假设一个对象经过的垃圾收集次数越多，能够得出：该对象存活时间就越长。
		 >>> 当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去。而新分配的内存都划分到集合B中去。当垃圾收集_始工作时，大多数情况都仅仅对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制须要处理的内存少了，效率自然就提高了。
		 >>> python 一共有3代
		 
> docker compose
	>> 在docker节点上，进行多容器应用的部署和管理。
		 >>> 多数的现代应用通过多个更小的服务互相协同来组成一个完整可用的应用。比如一个简单的示例应用可能由如下 4 个服务组成：web前端，订单管理，品类管理，后台数据库。通过一个yaml配置文件来实施部署。
