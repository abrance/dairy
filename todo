> 7.2


> 软件版本命名规范

du -d 1 /opt | sort -rh
curl get请求参数 & 需要转义符 https://blog.csdn.net/luosai19910103/article/details/100126003


protocol_version 对应表
0    未定义
1    HTTP1.0
2    HTTP1.1
3    HTTP2
4    HTTP3

db..aggregate([
    /* match pipeline */
    {
        "$sort": {
            "http_log.common_properties.start_time.seconds": -1
        }
    },
		{
				"$skip": 10
		},
		{
				"$limit": 10
		}
]);

apiDetail?mode=2&page=1&size=10
// login
curl -H "Content-Type: application/json" -X POST --data '{"mobile": "19999999999", "password":"123456"}'  http://192.192.100.70:20520/login
{"code":200,"data":{"token":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NTc5NjQ4NTcsImlhdCI6MTY1Nzk1NzY1NywibmFtZSI6IjE5OTk5OTk5OTk5In0.LyRPs6pTGdYy2z6SN0mCAlLUImf5iV-XRm7_VOGuT9A","username":"19999999999"},"msg":"ok"}

// 调用记录
curl -H "Content-Type: application/json" -X GET  http://192.192.100.70:20520/v1/access/apiDetail?mode=2&page=1&size=10


> TODO
	>> 调用记录 返回了全量数据，需要改为 分页传输
	>> 访问排行 根据筛选 返回响应的数据

	http://192.192.100.70:20520/v1/access/apiDetail?mode=2

	>> 加上盐值 即可实现完整登录逻辑
	
	>> 将存在性能问题的接口进行优化

	>> feature: 使用中间件将db还未初始化时，所有的前端请求拦截并返回 code: 501
	>> 没有集合的时候去查集合中的文档会发生什么？
	>> ss 项目 db collections 数目不定导致查表复杂度上升： envoy实例的个数对应collection的个数
		>>> 问题
			>>>> 后期页面可能
	>> ss 项目编译过程 部署过程 文档整理
	>> HA 代码接手
		
	>> 可视化功能相关日志统计
	>> 使用多路复用IO 模型

	>> 面试题参考答案
	
	>> BPF 书籍 P4 目录
	>> cilium 部署文档
		>>> 环境要求 内核 Linux 4.9 以上  Kubernetes >= 1.16 CNImode
		>>> k8s 环境
		>>> 下载 helm cilium 包
		>>> 安装 cilium
		>>> 修改 deployment
			tolerations:
			  - operator: Exists
		>>> 暴露 pod 
			kubectl port-forward -n kube-system svc/hubble-ui --address 0.0.0.0 --address :: 12000:80

	>> 清楚 cilium 内部的东西

	>> 71 73 78 79

	>> xDS 服务基本原理

	>> xds 服务器的 IP 地址使用浮动 IP 地址

> 重要不紧急
	>> upstream 测试用例
	>> 三大转换单元测试用例
	>> 联调测试用例

	>> traceroute
	>> emacs M-x rm-larger 实现 选中区域每行删掉一个 > 并缩进两格	
	>> 自动生成文档脚本
		>> 默认对每个函数生成相应的层级文档
		>> exclusive 对不想要的函数进行排除 exclusiveHeader exclusiveBody   header 表示这个函数不需要解析,  body 表示函数里面这一行不需要解析,  上面有一层 scope
		>> 单行函数注解(支持 code-region 第一行按照 funcionName 注释 格式编写)
	>> 执行进程时通过管理 PID 来优雅关闭进程
		>> 执行后台进程时，保存进程pid
		nohup ./server10000 & echo $! > server10000.pid
		>> python python-daemon 包实现了 context 进行 PID 进程管理


> 未解决 bug 
	>> sub_alt

> 已解决 bug

> 读书
	>> 精通git
	>> 程序员修炼之道
	>> 深入理解 linux 内核
	>> 深入理解Linux 网络内幕
	>> Raft 协议	
	>> 大规模分布式系统

> 每日
	>> 22 编译打包
		>>> /home/envoy/projects ./deploy.sh
	>> 70 更新webserver web
		>>> /opt/   ./main.sh

> call
	>> 家乐把代码先放到项目里面，进行ss编译部署测试
	>> 家乐现在将最新的放到 develop 分支，为了使用到最新的前端，使用了 x-apigateway-web develop 分支进行打包，后面 develop 分支需要合并到 main 分支，要记得 将 22 的 x-apigateway-web 切换回 main 分支


> gitlab release 接口
	https://blog.csdn.net/a112626290/article/details/105404318

> 修改时区
	>> ntpdate 时间同步后可能还是有时区对不上问题，这时可能需要修改时区

> 并发连接数和请求数
	>> 并发连接数 可以理解为同一时间 TCP 连接的个数，而请求数可能比这个值多一些，因为这些请求可能通过这些连接来传递数据


> sidecarProxy routerProxy
	>> what
		nodeType 节点类型 
	>> sidecarProxy
		SidecarProxy type is used for sidecar proxies in the application containers
	>> routerProxy
		Router type is used for standalone proxies acting as L7/L4 routers

> client-go   条件锁


> X网关的网络解决哪些问题
	>> 用户 API  负载均衡
	>> 用户 API SSL 卸载
	>> 用户 API 

> 数据中心流量分类
	>> 东西向流量
		>>> 数据中心内部服务器之间交互的流量，也叫东西向流量或者横向流量
	>> 南北向流量
		>>> 数据中心外部用户和内部服务器之间交互的流量


> 可视化相关元素
	1、不同运营商对应的api访问质量分布（运营商名称、访问总数、失败总数）,可以根据时间段（天、周、月、不限）来进行筛选
	2、省份访问排行（前10个，省份、api名称、总数）
	3、整体api调用排行（api名称、总数），可以根据时间段（天、周、月、不限）来进行筛选
	4、默认当日所有api访问总量、当日失败总数、当日总流量
	5、按状态码统计（404,500,200，其他）,可以根据时间段（天、周、月、不限）来进行筛选
	6、按路由行为统计（直接响应、重定向、转发）,可以根据时间段（天、周、月、不限）来进行筛选
	7、api总数（所有api的数量），总流量数
	8、api实时调用情况（滚动效果）（api、请求方法、流量、省份、状态、请求时间）
	9、api调用趋势（时间、调用次数），做成曲线图的形式
	10、api的每日调用情况（假设总共100个api，当时只调用了80个，则采用刻度表的形式，展示80%）

  针对于多套X网关，直接统计总数，做成下拉切换的形式


> 可视化功能相关日志统计 TODO
	>> models
		>>> cache 数据结构
		>>> mongodb models 建立
		>>> 每个表每个用到的字段都要写到文档
	>> 部署文档


> TCP 需要解决
	>> 拆包
		当客户端在短时间内，或者是并发下，发送几条序列时[0 1 2 3] [2 8 7] [9 88],在服务端有可能接收到的是[0 1 2 3 2 8 7 9 88]，但很显然，这是3条消息，需要在服务端进行拆包，分离成三条有效的消息才可以。
	>> 心跳
		当客户端和服务端连接后，客户端因为某些原因崩溃了，没有走正常的离线操作，那么这时，服务端无法感知到客户端的结束，会继续把持着连接，耗费资源，所以需要设定心跳。由客户端每隔一段时间发送一条消息，让服务端知道他还活着。
	>> 消息分离
		所有的客户端消息，都从同一个conn中留出，而不同的消息有不同的处理方法，请求参数，需要对拆分出来的消息进行分离，适用予不同的handler。
	>> 维护成本
		维护成本体现在两点。第一，从官方的库示例可以看出，底层的写法很多问题没有考虑到，仅仅是涉及到连接的建立和对发，在开发时，不同的使用者写法群魔乱舞，很难做到统一，人数越多越难维护。第二，仅使用基本包在需求迭代时，很容易让代码变得越来越臃肿，比如临时给你一个需求，要求像http那样，支持某一个handler的中间件。


> ss 数据大图
	>> 需求
		>>> 热力值统计（红点）
			>>>> 根据省市区分别进行热力值统计，需要 省级 市级 区级 标识 （时间概念: 每天凌晨到当下） (limit 10)
			select province_id, cnt(id) from access_log where $Y$m$D<time<$NOW group_by province_id; 省级
			select city_id, cnt(id) from access_log where $Y$m$D<time<$NOW and province_id = $province_id group_by city_id; 市级
			select distinct_id, cnt(id) from access_log where $Y$m$D<time<$NOW and city_id = $city_id group_by distinct_id; 区级
			
		>>> 实时API调用（蓝点）
			>>>> 实时 api 调用情况
				select src_region_id, dst_region_id, path, time from access_log order_by time desc; 最近的一个 api 调用


> 查询每个省 成功 失败 请求数 list
	$group: {_id : { province_id: $province_id, status_code: $status_code_field_name},  ...}
	

> 技术点
	>> 统计数量 	group_by分组查询
		.aggregate([{$match: {xxx: xxxx}}, {$group: {_id: region_id, cnt: {$sum: 1}}}])
	>> 时间筛选
		{time: {$gte: $Y$m$D, $lte: $NOW}}
	>> and关系
		{$and: [{id: xxx, age: xxx}]}
	>> 排序（倒序）
		.sort({time: -1})
		.order_by({time: -1})

> ss API 调用趋势
	>> 需求
		>>> 查询每天
			
				
> 需要重装为debian10 机器
	>> 192.192.100.72  192.192.100.73   192.192.100.78    192.192.100.37  80-82
	
> traceroute
	>> 概念
		traceroute 是Linux和Mac OS等系统默认提供的路由追踪小程序，能探测数据包从源地址到目的地址经过的路由器的IP地址
	>> 原理
		  1. 从源地址发出一个UDP探测包到目的地址，并将TTL设置为1；
			2. 到达路由器时，将TTL减1；
			3. 当TTL变为0时，包被丢弃，路由器向源地址发回一个ICMP超时通知（ICMP Time Exceeded Message），内含发送IP包的源地址，IP包的所有内容及路由器的IP地址；
			4. 当源地址收到该ICMP包时，显示这一跳路由信息；
			5. 重复1～5，并每次设置TTL加1；
			6. 直至目标地址收到探测数据包，并返回端口不可达通知（ICMP Port Unreachable）；
			7. 当源地址收到ICMP Port Unreachable包时停止traceroute。
	>> 常用选项
	>> e.g.
		>>> traceroute www.baidu.com


> tmux 导出缓冲区日志
	>> 捕捉 缓冲区位置
		-S 起始位置 1025 -E 终点位置   （起始和终点位置可以通过 copy-mode 右上方数字确定）
		-t 1  指定pane 编号  （pane编号可以通过 C-b w 显示的序号来确定）
		tmux capture-pane -S -1025 -E -1 -t 1
	>> 输出位置
		tmux save-buffer output.log
		最后输出到 /root/output.log 里面
	>> e.g.
		tmux capture-pane -S -1025 -E -1 -t 1
		tmux save-buffer output.log
		

> 37 
> 69 演示
> 72 伟彪测试环境
> 73 
> 78
> 79 

> 项目

> HA
	>> 问题
		>>> 整体架构
		>>> 数据面浮动IP来源
		>>> 浮动IP下发方式
		>>> 数据面浮动IP引入标签的目的
		>>> 如何管理其他进程
		>>> 本程序异常重启时如何加载数据
		>>> scripts文件夹里面的脚本逻辑
		>>> 主备决策的逻辑
		>>> 如何编译项目
		>>> 为什么需要root权限

> installer 
	>> 问题
		>>> 本项目的用途
		>>> systemctl命令的用法
		>>> systemd服务的编写
		>>> 整体架构
		>>> 脚本依赖的外部程序
		>>> 目前未完成的需求
		>>> 分发密钥思路
		>>> 初始化配置保存的临时路径
		>>> 安装时拷贝配置的远程临时路径
		>>> ca模块的特殊处理与其他模块对其引用方式
		>>> 卸载脚本与安装脚本的执行方式差异
		>>> 如何增加一个模块的脚本,需要新增、改动哪些文件
		>>> 为什么webserver在reinstall后原有用户失效,能否解决
		>>> reinstall脚本为什么只能在上次部署的节点上运行
		>>> k8s/scripts/init.sh的逻辑里面,shared文件夹的用处
		>>> scripts/install.sh里面为什么要并行安装,如何检查安装过程是否发生错误
		>>> 卸载的时候是串行还是并行
		>>> 目前有多少个模块,有哪些模块的文件结构与其他模块不同,为什么
		>>> envoy热重启命令及其实现(可选)
		>>> envoy admin端口目前侦听的地址和端口
		>>> dam&gateway项目侦听的地址和端口
		>>> webserver侦听地址和端口
		>>> etcd,apiserver侦听地址和端口
		>>> 项目目前在哪些OS上验证过可用
		>>> envoy链接方式,以及对GLIBC版本的依赖(可选)
		>>> envoy链接发生在初始化阶段还是安装阶段
		>>> 哪些程序其实不需要root权限
		>>> 如何在systemd里面限制Capability

> file-syncer 
	>> 问题
		>>> kubebuilder创建项目的方式
		>>> 整体架构
		>>> 启动参数node-ip,cluster的意义
		>>> 如何编译项目
		>>> 为什么需要root权限
		>>> 获取插件crd列表的逻辑
		>>> SFTPFileManagerImpl.LocalMove的实现使用命令行的理由
		>>> op字段的取值及含义
		>>> op==sync-plugin时,实际的处理函数入口
		>>> plugins资源的list/watch命名空间
		>>> 修改api/v1/filesyncjob_types.go文件后,如何重新生成crd定义yaml

> device-manager 
	>> 问题
		>>> 该项目计划的用途
		>>> 该项目是否还需要进行
		>>> 需求
		>>> 架构
		>>> 需求完成度


## 预研工作
需要了解的内容
		>>> netlink协议
		>>> 如何使用netlink来获取路由表,邻居表(go语言)
		>>> ebpf程序常见的加载器
		>>> go语言创建ebpf map和CRUD接口

echo "  cabundle: 1"| sed -i  's/\("cabundle":"\).*/\1'"3"'",/g'
awk -F: '/should-replace/{$2=($2==""?"true":"false")}1'


> HA
	>> 概念
		>>> HA 
		HA 是为整套系统（包含x网关）提供高可用特性的模块，理论上不依赖其他模块。
		HA 分为 ControllerManager（主备决策） monitor（etcd监视器） ControlPlaneAgent（管理面worker） ProxyAgent（数据面worker）等模块
	>> 解决哪些问题
		>>> 如何感知节点不可用？
		>>> 如何保证切换流程执行正确性？
		>>> 如何保证绝不发生脑裂？
	>> HOW
		>>> 如何感知节点不可用？
			>>>> 概念
				HA 的存在意义(主要功能)为在用户无感知的情况下进行故障转移, 想要实现这个功能, 必须先感知节点的状态, 根据节点状态进行相应的操作;
				可能出现的环境不可用有很多: 网络, 计算资源, 内存资源, 存储资源等硬件资源, 和组件异常, 行为异常, 数据异常等软件资源;
				因为开发周期和DRY原则, 我们复用 etcd 的高可用决策机制, 去主动感知etcd的可用状态, 而放弃做一个 真正的感知环境 的组件, 来实现感知节点状态;这个感知功能的基础, 建立在我们相信etcd所依赖的环境正是整套系统所依赖的环境, etcd的感知正确性是可靠的, etcd的高可用是可靠的(高可用 高性能 高扩展, 我们可能只实现了高可用), 
			>>>> etcd 高可用机制实现了高可用吗?实现的是我们所需的高可用吗?
				etcd 高可用使用了 raft协议实现一致性 关于 raft的实现在 etcd 源码 /raft 目录
		>>> 如何保证切换流程执行正确性？
			>>>> 
		>>> 如何保证绝不发生脑裂？
			>>>> 
	>> 架构图
------------------------------------------------------------
                                               ┌──────────────┐
                                        ┌────► │ctlplane-agent│
                                        │      └──────────────┘
 ┌──────────┐           ┌──────────┐    │
 │ monitor  ├─────────► │ manager  ├────┤
 └────┬─────┘           └──────────┘    │
      │                                 │       ┌─────────────┐
      │                                 └────►  │ proxy-agent │
      ▼                                         └─────────────┘
node status
------------------------------------------------------------
